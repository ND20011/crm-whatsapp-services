# Soluci√≥n a los Errores 429 (Too Many Requests)

## Problema Identificado

El dashboard estaba generando errores `429 (Too Many Requests)` debido a que hac√≠a m√∫ltiples llamadas simult√°neas a la API cuando se cargaba, excediendo los l√≠mites de rate limiting configurados en el backend.

### Errores espec√≠ficos encontrados:
- `GET http://localhost:3000/api/contacts 429 (Too Many Requests)`
- `GET http://localhost:3000/api/messages/conversations 429 (Too Many Requests)`
- `GET http://localhost:3000/api/messages/whatsapp/status/public 429 (Too Many Requests)`
- `GET http://localhost:3000/api/messages/bot/status/public 429 (Too Many Requests)`
- `GET http://localhost:3000/api/messages/bot/quota/public 429 (Too Many Requests)`
- `GET http://localhost:3000/api/messages/templates 429 (Too Many Requests)`

## Causas Identificadas

1. **Rate limiting global muy restrictivo**: 100 requests por 15 minutos por IP
2. **M√∫ltiples llamadas simult√°neas**: El dashboard hac√≠a 7 llamadas API simult√°neas al cargar
3. **Sin cache**: No hab√≠a mecanismo de cache para evitar llamadas redundantes

## Soluciones Implementadas

### 1. Backend: Ajuste del Rate Limiting Global

**Archivo**: `/backend/src/app.js`

```javascript
// Rate Limiting mejorado
const limiter = rateLimit({
    windowMs: 15 * 60 * 1000, // 15 minutos
    max: process.env.NODE_ENV === 'production' ? 500 : 1000, // M√°s requests en desarrollo
    message: {
        error: 'Demasiadas solicitudes desde esta IP, intenta de nuevo en 15 minutos.'
    },
    standardHeaders: true, // Return rate limit info in the `RateLimit-*` headers
    legacyHeaders: false, // Disable the `X-RateLimit-*` headers
});
```

**Cambios**:
- ‚úÖ Aument√≥ l√≠mite de 100 a 1000 requests en desarrollo
- ‚úÖ Aument√≥ l√≠mite de 100 a 500 requests en producci√≥n
- ‚úÖ A√±adi√≥ headers est√°ndar para informaci√≥n de rate limiting

### 2. Frontend: Sistema de Cache en Dashboard Service

**Archivo**: `/frontend/src/app/core/services/dashboard.service.ts`

```typescript
// Cache para reducir llamadas a la API
private cache = new Map<string, { data: any, timestamp: number }>();
private readonly CACHE_DURATION = 30000; // 30 segundos

// M√©todos de cache implementados
private getCachedData<T>(key: string): T | null
private setCachedData(key: string, data: any): void
private requestWithCache<T>(key: string, httpRequest: Observable<T>): Observable<T>
```

**Beneficios**:
- ‚úÖ Cache de 30 segundos para todas las respuestas
- ‚úÖ Evita llamadas redundantes a la API
- ‚úÖ Mejora la experiencia del usuario

### 3. Frontend: Carga Secuencial con Delays

**Archivo**: `/frontend/src/app/core/services/dashboard.service.ts`

```typescript
// Requests secuenciales con delays para evitar rate limiting
getDashboardStats(): Observable<DashboardResponse> {
    return of(null).pipe(
        // Primero contactos
        concatMap(() => /* contactos con delay 100ms */),
        // Luego templates  
        concatMap(() => /* templates con delay 100ms */),
        // Finalmente conversaciones
        concatMap(() => /* conversaciones con delay 100ms */)
    );
}
```

**Archivo**: `/frontend/src/app/features/dashboard/dashboard.component.ts`

```typescript
// Carga secuencial en lugar de simult√°nea
// 1. Stats principales (inmediato)
// 2. Actividad reciente (delay 200ms)  
// 3. Estados del bot y WhatsApp (delay 400ms)
```

**Beneficios**:
- ‚úÖ Reduce picos de requests simult√°neos
- ‚úÖ Distribuye la carga en el tiempo
- ‚úÖ Mantiene la funcionalidad completa

### 4. Frontend: Optimizaci√≥n de M√©todos de Estado

Todos los m√©todos de estado del bot y WhatsApp ahora usan cache:

```typescript
getBotStatus(): Observable<ApiResponse> {
    return this.requestWithCache('bot_status', /* HTTP request */);
}

getBotQuota(): Observable<ApiResponse> {
    return this.requestWithCache('bot_quota', /* HTTP request */);
}

getWhatsAppStatus(): Observable<ApiResponse> {
    return this.requestWithCache('whatsapp_status', /* HTTP request */);
}
```

## Resultados Esperados

1. **Eliminaci√≥n de errores 429**: No m√°s "Too Many Requests"
2. **Mejor performance**: Cache reduce llamadas innecesarias
3. **Carga m√°s suave**: Requests distribuidos en el tiempo
4. **Mejor experiencia**: Loading m√°s gradual y estable

## Configuraci√≥n Flexible

- **Desarrollo**: 1000 requests por 15 minutos (muy permisivo)
- **Producci√≥n**: 500 requests por 15 minutos (balanceado)
- **Cache**: 30 segundos (configurable en `CACHE_DURATION`)
- **Delays**: 100-400ms entre requests (configurable)

## Pr√≥ximos Pasos

Para probar los cambios:

1. **Reiniciar backend**:
   ```bash
   cd backend
   npm start
   ```

2. **Reiniciar frontend**:
   ```bash
   cd frontend  
   npm start
   ```

3. **Verificar en navegador**:
   - Abrir DevTools > Network
   - Navegar al dashboard
   - Verificar que no aparezcan errores 429
   - Observar el patr√≥n de carga secuencial

## Monitoreo

Los logs del navegador mostrar√°n:
- `üì¶ DashboardService: Usando datos en cache para {key}` (cuando usa cache)
- `üìä Dashboard secondary data loaded` (carga secuencial funcionando)
- Ausencia de errores 429 en la consola

La implementaci√≥n es retrocompatible y no requiere cambios en la base de datos ni en otros componentes.
